{"name":"Similar Language Detection","tagline":" A machine learning system for classifying texts written in similar languages.","body":"## Overview\r\nMachine detection of languages of written texts is a solved problem under certain circumstances; disparate languages like French and English have such different vocabularies that an algorithm can distinguish them simply by looking up words in a dictionary. But if we have short texts, say tweets, all written in Portuguese, can a machine decide which authors/users are from Brazil and which ones are from Portugal? Similarly, it's important to classify webpages or blogs by which variety of Spanish they use; one can imagine that very different ads might need to be pushed to the page of a Mexican blogger from a Argentine one, although they may both be writing about their love of gatos.\r\n\r\nWe present here a machine learning system that demonstrates a novel hierarchical method to classify sentences written in very similar languages or variations of languages. It was done as a term project for CS229 Machine Learning at Stanford University in Fall 2015. The repository contains training and testing data we used to develop the system, code, and a paper presenting our findings. The hierarchical nature of our system renders it robustness and scalability as well as competitive accuracy of classification.\r\n\r\nWe demonstrate our method by contributing to the DSL-2015 Shared Task. More information about the task can be found in this github [repo](https://github.com/Simdiva/DSL-Task/tree/master/data/DSLCC-v2.0/). The Task provide a training corpus consisting of sentences from journalistic articles written in 13 languages. The 13 languages are divided into six language groups, within each the languages are very similar and difficult to distinguish from one another. The table below lists the 13 languages and their division into groups. Test datasets with and without labels are also provided by the task. More details on the data sets can be found in the DSL-Task github [repo](https://github.com/Simdiva/DSL-Task/blob/master/data/DSLCC-v2.0/train-dev/README.md). \r\n\r\n| Langugae group             | Languages                                               |\r\n| -------------------------- | ------------------------------------------------------- |\r\n| South-Eastern Slavic (ses) | Bulgarian (bg), Macedonian (mk)                         |\r\n| South-Western Slavic (sws) | Bosnian (bs), Croatian (hr), Serbian (sr)               |\r\n| West Slavic (ws)           | Czech (cz), Slovak (sk)                                 |\r\n| Spanish (es)               | Argentine Spanish (esar), Peninsular Spanish (eses)     |\r\n| Portuguese (pt)            | Brazilian Portuguese (ptbr), European Portuguese (ptpt) |\r\n| Austronesian (aus)         | Indonesian (id), Malay (my)                             |\r\n\r\n\r\nOur approach for classification is a two-level hierarchy. We first identify if a sentence belongs to a language group, which is trivial and can be done with a simple method; within each language group, we then train a support vector machine or ensembles of SVMs to pinpoint which language to label the sentence (see schematic below). This method is easily scalable to include tens and hundreds of languages and incorporate more training data. At the language group level, training the classifier involves word-counting and identifying most common words within languages; this can be scaled up using a cluster file system and a MapReduce program. Within each language group, there are typically only 2 to 3 languages; this also makes parallelization easy and the number of features used in SVMs well-controlled.\r\n\r\n![schematic](https://raw.githubusercontent.com/shenglan0407/Similar_language_identification/master/writing/schema.jpeg)\r\n\r\n## Performance\r\nWe tested our method with 1000 test examples per language, using [this dataset](https://github.com/Simdiva/DSL-Task/blob/master/data/DSLCC-v2.0/gold/test-gold.txt) from the DSL-Task. The confusion matrix summarizes our results.\r\n\r\n![confusion matrix](https://raw.githubusercontent.com/shenglan0407/Similar_language_identification/master/writing/Final_confusion_matrix.png)\r\nGroup accuracy represents the fraction of test examples correctly classified into their respective language groups during the first step of the hierarchical method. The upshot is using only the 1000 most frequently used words, a small fraction of all available vocabulary in each language, we can achieve near perfect accuracy distinguishing between language groups (we choose to combine the South-western Slavic and the West Slavic groups into one group as that increases our final accuracy). The final accuracy indicates the fraction of test examples correctly labeled by language after the second step of our methods involving ensemble SVMs. After implementing a feature selection procedure with a tfidf-type ranking index, the number of features for these SVMs within language groups are in the order of tens of thousands, which are very manageable and do not require extraordinary computation resources. In short, in designing our method we try to make it efficient and scalable. Details on the method are in our [paper](https://github.com/shenglan0407/Similar_language_identification/blob/master/writing/final.pdf)\r\n\r\n\r\n## Workflow\r\nThe diagram below summarizes the basic steps to go from a training corpus to our validated hierarchical method that will automatically detect the language a sentence is written in. \r\n\r\n![workflow](https://raw.githubusercontent.com/shenglan0407/Similar_language_identification/master/writing/workflow_diagram.png)\r\n\r\nThe language group classifier (word frequency) and the individual language classifier (ensemble SVM) are first trained. They are then validated and fine tuned using the devel data before being deployed to predict the labels of the test data. A user can use the python scripts in this repository to train her own system.\r\n\r\n## Credit\r\nDaniel Levy and Shenglan Qiao (the Authors) contributed equally to this project.\r\n\r\nCopyright 2015 Stanford University and the Authors\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}